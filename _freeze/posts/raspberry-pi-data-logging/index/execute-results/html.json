{
  "hash": "ece6645277309cac1b1c5bb04ef0993f",
  "result": {
    "markdown": "---\ntitle: \"Dashboards and data logging with a Raspberry Pi\"\nauthor: \"Sam Vaughan\"\ndate: \"2023-04-25\"\ncategories: [raspberry-pi]\nhighlight-style: github\nengine: knitr\nexecute:\n    eval: false\n---\n\n# Dashboards and data logging with a Raspberry Pi\n\nI recently brought a couple of atmospheric sensors for my Raspberry Pi to measure temperature and air pressure. This is a quick post about how I've set everything up to collect the data, save it to an [Influx database](https://www.influxdata.com/) and display it with a [Grafana](https://grafana.com/) dashboard. \n\n## Setting up the Pi\n\nI'm using a Raspberry Pi Zero and the PiicoDev [precision temperature](https://core-electronics.com.au/piicodev-precision-temperature-sensor-tmp117.html) and [pressure](https://core-electronics.com.au/piicodev-pressure-sensor-ms5637.html) sensors, purchased from [Core Electronics](https://core-electronics.com.au/). They were incredibly easy to set up- just plug and play into a PiicoDev adaptor attached to the Pi's header pins. The Pi itself was a standard configuration, just Raspberry Pi OS (5.15.84+ \"Bullseye\"). \n\nNext, initialise the I2C interface in the Raspberry Pi configuration menu or by using \n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo raspi-config nonint do_i2c 0\n```\n:::\n\n\nat the command line. Note that the zero means \"on\" here! We next need the `piicodev` python package from `pip`:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npip install piicodev\n```\n:::\n\n\nUsing the `piicodev` package, we can then grab values from these sensors in the following way:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# Import the packages\nfrom PiicoDev_TMP117 import PiicoDev_TMP117 # temperature sensos\nfrom PiicoDev_MS5637 import PiicoDev_MS5637 # pressure sensor\n\n# initialise the sensors\ntempSensor = PiicoDev_TMP117()\npressure = PiicoDev_MS5637()\n\n# read the values\ntempC = tempSensor.readTempC()\npress_hPa = pressure.read_pressure()\n```\n:::\n\n\nSo if you want to just show those measurements on the commandline, you can just wrap this in a `while` loop and add some print statements. I wanted to have things running in the background and the results being saved in a nice format, however, so we also need a database to write to and a way to plot the results.\n\n## Making an Influx database\n\nWhilst we could write things to a csv file, having a proper database connection has a number of benefits (such as scaling better if/when you have multiple sensors in different locations, and interfacing very nicely with the dashboard service we'll be using). InfluxDB is an open-source platform built for working with time-series data, so it's a sensible choice. \n\nFirst, we install it on our Pi. Which version? The latest online is Version 2.7, but that's only available for 64-bit architectures, which my Pi Zero sadly isn't. As of April 2023, version 1.6.7 is available in the standard Raspbian channels, but I'm using version 1.8.1 here. \n\nTo get that, we need to add the Influx repository\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncurl https://repos.influxdata.com/influxdata-archive.key | gpg --dearmor | sudo tee /usr/share/keyrings/influxdb-archive-keyring.gpg >/dev/null\n```\n:::\n\n\nand then add that to our source list. Note that `$(lsb_release -cs)` gets our version of Raspberry Pi OS, which in my case is \"Bullseye\".\n\n\n::: {.cell}\n\n```{.bash .cell-code}\necho \"deb [signed-by=/usr/share/keyrings/influxdb-archive-keyring.gpg] https://repos.influxdata.com/debian $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/influxdb.list\n```\n:::\n\n\nWe can then just do:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo apt update && sudo apt install influxdb\n```\n:::\n\n\nIf everything goes well, that should all finish without any errors. We then need to start the influx service running, and make sure that it starts whenever our Pi boots up. \n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo systemctl unmask influxdb\nsudo systemctl enable influxdb\nsudo systemctl start influxdb\n```\n:::\n\n\nYou should now be able to run `influx` at the command line, which changes to the `influx` prompt. We need to create a database and make a new user, which we can do with the following commands. Here the new user will be called `grafana`, with `grafana` as the password. \n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncreate database home_measurements\nuse home_measurements\n\ncreate user grafana with password 'grafana' with all privileges\ngrant all privileges on home to grafana\n```\n:::\n\n\n## Writing to our database\n\nWe can write our measurments to our database with a short python script. Firstly, we need the `influxdb` python library, which we can get using `pip`:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npip install influxdb\n```\n:::\n\n\nNote that I'm _not_ using the very similarly-named `influxdb-client` library- they have very different syntaxes! \n\nIn our python script, we can open a connection to this DB with the following:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom influxdb import InfluxDBClient\n# Connect to our database\nhost = 'localhost'\nport = 8086\nusername = 'grafana'\npassword = 'grafana'\ndatabase = 'home_measurements'\n\nclient = InfluxDBClient(host=host,\n                        port=port,\n                        username=username,\n                        password=password,\n                        database=database)\n```\n:::\n\n\nWrites to the database need to be in JSON format, and the following syntax seems to be standard. In my case, I have `sensor_location_string='indoor'` and `sensor_location_description_string='living_room'`. We'll be able to group/subset our database by these variables later.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmeasurements = [\n    {\n        \"measurement\": sensor_location_string,\n        \"tags\": {\n            \"location\": sensor_location_description_string},\n        \"time\": timestamp,\n        \"fields\": {\n            \"temperature\" : tempC,\n            \"pressure\": press_hPa}\n    }]\n\n# Write them to our database\nclient.write_points(measurements)\n```\n:::\n\n\nMy entire script is here:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom PiicoDev_TMP117 import PiicoDev_TMP117\nfrom PiicoDev_MS5637 import PiicoDev_MS5637\nfrom datetime import datetime\nfrom influxdb import InfluxDBClient\n\n# initialise the sensors\ntempSensor = PiicoDev_TMP117()\npressure = PiicoDev_MS5637()\n\n# Connect to our database\nhost = 'localhost'\nport = 8086\nusername = 'grafana'\npassword = 'grafana'\ndatabase = 'home_measurements'\n\nclient = InfluxDBClient(host=host,\n                        port=port,\n                        username=username,\n                        password=password,\n                        database=database)\n\n\n# Get our time measurements\nnow = datetime.now()\ntimestamp = datetime.utcnow()\ntimestamp_human = now.strftime(\"%d-%m-%YT%H:%M:%S\")\n\n# Measure the sensors\ntempC = tempSensor.readTempC()\npress_hPa = pressure.read_pressure()\n\n# Arrange in the correct JSON\nmeasurements = [\n    {\n        \"measurement\": \"indoor\",\n        \"tags\": {\n            \"location\": \"living_room\"},\n        \"time\": timestamp,\n        \"fields\": {\n            \"temperature\" : tempC,\n            \"pressure\": press_hPa}\n    }]\n\n# Write them to our database\nclient.write_points(measurements)\n```\n:::\n\n\n### Running this script on a schedule\n\nThe script makes a single measurement. We can schedule it using the unix command-line utility `cron`. Run `crontab -e` and you should see the following:\n\n```\n# Edit this file to introduce tasks to be run by cron.\n# \n# Each task to run has to be defined through a single line\n# indicating with different fields when the task will be run\n# and what command to run for the task\n# \n# To define the time you can provide concrete values for\n# minute (m), hour (h), day of month (dom), month (mon),\n# and day of week (dow) or use '*' in these fields (for 'any').\n# \n# Notice that tasks will be started based on the cron's system\n# daemon's notion of time and timezones.\n# \n# Output of the crontab jobs (including errors) is sent through\n# email to the user the crontab file belongs to (unless redirected).\n# \n# For example, you can run a backup of all your user accounts\n# at 5 a.m every week with:\n# 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/\n# \n# For more information see the manual pages of crontab(5) and cron(8)\n# \n# m h  dom mon dow   command\n\n```\n\nAdd the following write at the end:\n\n```\n*/5 * * * * /usr/bin/python /path/to/your/script/script.py &\n```\n\nThis tells our Pi to execute the command `/usr/bin/python /path/to/your/script/script.py &` at intervals of 5 minutes. Give it a go!\n\n## Displaying the results with Grafana\n\nNext we'll install grafana, an open source dashboard service. To get it on the Pi, we need to add the Grafana key used to authenticate packages, add the repository to the source list, update the package list and then finally install `grafana-rpi` [^1]\n\n[^1]: Note that I needed to run `sudo apt-get install -y grafana-rpi`, and _not_ `sudo apt-get install -y grafana` (as, for example, the Grafana docs suggest [here](https://grafana.com/tutorials/install-grafana-on-raspberry-pi/)). When I ran `sudo apt-get install -y grafana`, my grafana server refused to start, similary to [this](https://github.com/grafana/grafana/issues/56773) github issue.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nwget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -\necho \"deb https://packages.grafana.com/oss/deb stable main\" | sudo tee -a /etc/apt/sources.list.d/grafana.list\nsudo apt-get update\nsudo apt-get install -y grafana-rpi\n```\n:::\n\n\nWe then need to start the Grafana instance running, and also make sure that it starts whenever the Pi boots up.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo systemctl unmask grafana-server.service\nsudo systemctl start grafana-server\nsudo systemctl enable grafana-server.service\n```\n:::\n\n\nNearly there! We just need to point our Grafana instance to our database, which we do using the GUI. ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}